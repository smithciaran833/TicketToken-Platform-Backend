# Blockchain Service - Known Problems & Issues

**Last Updated:** January 6, 2026  
**Service:** blockchain-service (TicketToken Platform)  
**Analysis Source:** Comprehensive codebase review (19 directories, 120+ files)

---

## üî¥ CRITICAL ISSUES (Must Fix Immediately)

### 1. FeeManager - Undefined Fees Configuration
**File:** `src/wallets/feeManager.ts:10`  
**Severity:** üî¥ CRITICAL - Service Breaking  
**Impact:** All fee calculations will fail with runtime errors

**Problem:**
```typescript
constructor(connection: Connection) {
  this.connection = connection;
  // this.fees = config.fees;  // COMMENTED OUT!
}

calculateMintingFee(): FeeBreakdown {
  return {
    rentExemption: this.fees.rentExemption,  // ‚ùå this.fees is undefined
    transactionFee: this.fees.transactionFee, // ‚ùå crashes here
    // ...
  };
}
```

**Root Cause:** Line 10 has `this.fees = config.fees;` commented out, so `this.fees` is never initialized.

**Consequence:**
- Any call to `calculateMintingFee()`, `calculateTransferFee()`, or `calculateBurnFee()` will throw `Cannot read property 'rentExemption' of undefined`
- Fee estimation will completely fail
- Balance checks will fail
- Service is non-functional for any operations requiring fee calculation

**Fix:**
```typescript
constructor(connection: Connection) {
  this.connection = connection;
  this.fees = config.fees; // UNCOMMENT THIS LINE
}
```

**Alternative:** Define a fallback default fees object if `config.fees` doesn't exist.

---

### 2. Missing TreasuryWalletService Implementation
**File:** `src/services/TreasuryWalletService.ts`  
**Severity:** üî¥ CRITICAL - Missing Component  
**Impact:** Treasury operations completely absent

**Problem:**
```bash
cat: src/services/TreasuryWalletService.ts: No such file or directory
```

**Root Cause:** File doesn't exist but may be referenced elsewhere in the codebase.

**Consequence:**
- Treasury wallet service operations unavailable
- Cannot perform treasury-related queries or operations
- May cause import errors if referenced

**Investigation Needed:**
1. Search codebase for `import.*TreasuryWalletService` to find dependencies
2. Determine if this service is needed or can be removed from imports
3. If needed, implement the service based on requirements

---

### 3. Secrets Manager Integration Not Verified
**File:** `src/config/secrets.ts`  
**Severity:** üî¥ CRITICAL - Security & Production Readiness  
**Impact:** Production deployment may fail

**Problem:**
The code references AWS Secrets Manager and Vault integration (AUDIT FIX #1, #69), but:
- No actual implementation visible in the analyzed files
- No verification of AWS SDK integration
- No verification of Vault client integration
- No error handling for secrets loading failures at startup

**Consequence:**
- Production startup may fail if secrets cannot be loaded
- No fallback mechanism for secrets loading
- Potential security issue if secrets are hardcoded instead
- Cannot verify AUDIT FIX #1 and #69 are actually implemented

**Investigation Needed:**
1. Verify `src/config/secrets.ts` contains actual AWS/Vault integration code
2. Verify secrets are loaded at application startup
3. Verify startup fails gracefully if secrets unavailable
4. Add integration tests for secrets loading

---

### 4. Database Transaction Error Handling Gap
**File:** Multiple locations in transaction processing  
**Severity:** üî¥ CRITICAL - Data Integrity  
**Impact:** Silent data corruption possible

**Problem:**
Many database operations don't properly handle transaction rollback scenarios:
```typescript
// Example from mintQueue.ts
await this.pool.query(`UPDATE tickets SET status = 'MINTING' WHERE id = $1`, [ticketId]);
// If mint fails here, ticket is stuck in MINTING state forever
const mintResult = await this.metaplexService.mintNFT(params);
// No rollback on failure
```

**Root Cause:**
- Not all DB operations wrapped in transactions
- Missing `try-catch-finally` with rollback
- No compensation logic for partial failures

**Consequence:**
- Tickets stuck in intermediate states (MINTING, TRANSFERRING)
- Database and blockchain state divergence
- Manual intervention required to fix orphaned records

**Fix Locations:**
- `src/queues/mintQueue.ts` - Wrap mint flow in transaction
- `src/processors/transactionProcessor.ts` - Add rollback on parse failures
- `src/wallets/userWallet.ts` - Ensure soft delete is transactional

**Recommended Pattern:**
```typescript
const client = await this.pool.connect();
try {
  await client.query('BEGIN');
  // ... operations
  await client.query('COMMIT');
} catch (error) {
  await client.query('ROLLBACK');
  // ... compensation logic
  throw error;
} finally {
  client.release();
}
```

---

### 5. Missing Production Environment Validation
**File:** `src/config/validate.ts`, `src/index.ts`  
**Severity:** üî¥ CRITICAL - Production Safety  
**Impact:** Production deployment with insecure configuration

**Problem:**
Configuration validation doesn't enforce all production requirements at startup:

**Missing Validations:**
- ‚úÖ JWT_SECRET minimum 32 chars (AUDIT #57) - implemented
- ‚ùå HTTPS enforcement on service URLs not validated at startup
- ‚ùå Redis TLS (rediss://) not enforced in production
- ‚ùå Database SSL not enforced in production
- ‚ùå Public RPC URLs not rejected in production
- ‚ùå Default/weak secrets not rejected in production
- ‚ùå Treasury whitelist not validated at startup

**Consequence:**
- Service may start in production with insecure configuration
- SSL/TLS connections may fail silently
- Security vulnerabilities in production
- Audit compliance failures

**Fix:**
Add comprehensive startup validation in `validateConfigOrExit()`:
```typescript
if (process.env.NODE_ENV === 'production') {
  // Enforce HTTPS
  if (!config.services.mintingServiceUrl.startsWith('https://')) {
    throw new Error('HTTPS required for minting service URL in production');
  }
  
  // Enforce Redis TLS
  if (!config.redis.url.startsWith('rediss://')) {
    throw new Error('Redis TLS (rediss://) required in production');
  }
  
  // Reject public RPCs
  const publicRpcs = ['api.mainnet-beta.solana.com', 'api.devnet.solana.com'];
  if (publicRpcs.some(rpc => config.solana.rpcUrl.includes(rpc))) {
    throw new Error('Public RPC URLs not allowed in production');
  }
  
  // Validate treasury whitelist
  if (config.treasuryWhitelist.length === 0) {
    throw new Error('Treasury whitelist cannot be empty');
  }
}
```

---

### 6. Race Condition in Transaction Monitor
**File:** `src/listeners/transactionMonitor.ts`  
**Severity:** üî¥ CRITICAL - Data Race  
**Impact:** Duplicate processing, memory leaks

**Problem:**
`pendingTransactions` Map is accessed without proper synchronization:
```typescript
addPendingTransaction(signature: string, ticketId: string) {
  // ‚ùå No check if already exists before adding
  this.pendingTransactions.set(signature, {
    ticketId,
    addedAt: Date.now(),
    attempts: 0
  });
  
  if (!this.pollingInterval) {
    this.startPolling(); // Could be called multiple times
  }
}

checkTransaction(signature: string) {
  const pending = this.pendingTransactions.get(signature);
  // ‚ùå Another thread could delete this between get and next line
  if (!pending) return;
  
  // ... async operations ...
  
  this.pendingTransactions.delete(signature);
  // ‚ùå Could delete wrong transaction if signature reused
}
```

**Root Cause:**
- No locks on `pendingTransactions` Map
- No atomic check-and-set operations
- Concurrent access from multiple listeners
- No protection against duplicate signature additions

**Consequence:**
- Same transaction monitored multiple times
- Memory leak from never-removed entries
- Race condition in finalization logic
- Duplicate database updates

**Fix:**
Use distributed locking or implement atomic operations:
```typescript
async addPendingTransaction(signature: string, ticketId: string) {
  const lockKey = `tx-monitor:${signature}`;
  await withLock(lockKey, 5000, async () => {
    if (this.pendingTransactions.has(signature)) {
      return; // Already being monitored
    }
    
    this.pendingTransactions.set(signature, {
      ticketId,
      addedAt: Date.now(),
      attempts: 0
    });
  });
}
```

---

## üü† HIGH PRIORITY ISSUES (Fix Soon)

### 7. Memory Leak in Event Deduplication
**File:** `src/listeners/programListener.ts`  
**Severity:** üü† HIGH - Memory Leak  
**Impact:** Service crashes after extended runtime

**Problem:**
No cleanup mechanism for processed events tracking:
```typescript
private processedEvents = new Set<string>();

handleAccountChange(accountInfo: AccountInfo, context: Context) {
  const eventId = this.generateEventId(signature, slot);
  
  if (this.processedEvents.has(eventId)) {
    return; // Skip duplicate
  }
  
  this.processedEvents.add(eventId); // ‚ùå Never removed!
  // ... process event
}
```

**Root Cause:**
- `processedEvents` Set grows unbounded
- No TTL or size limit
- No periodic cleanup

**Consequence:**
- Memory usage grows continuously
- Service crashes with OOM after processing millions of events
- Restart required to clear memory

**Fix:**
Implement LRU cache with size limit or TTL-based cleanup:
```typescript
private processedEvents = new LRUCache<string, boolean>({
  max: 100000, // Keep last 100k events
  ttl: 1000 * 60 * 60 // 1 hour TTL
});

// OR use Redis-backed deduplication with TTL
```

---

### 8. Insufficient Circuit Breaker Coverage
**File:** `src/utils/circuit-breaker.ts`  
**Severity:** üü† HIGH - Resilience  
**Impact:** Cascading failures not prevented

**Problem:**
Pre-configured circuit breakers exist for:
- ‚úÖ solana-rpc
- ‚úÖ treasury-wallet  
- ‚úÖ database

**Missing Circuit Breakers:**
- ‚ùå Metaplex minting operations (can fail for extended periods)
- ‚ùå Bundlr metadata uploads (external service)
- ‚ùå RabbitMQ connections (queue operations)
- ‚ùå Internal service calls (minting-service proxy)
- ‚ùå Redis operations (cache, rate limiting, locks)

**Consequence:**
- Metaplex failures cause unlimited retries
- Bundlr outages block all mints indefinitely
- No graceful degradation for external services
- Resource exhaustion from failing operations

**Fix:**
Add circuit breakers for all external dependencies:
```typescript
configureCircuit('metaplex', {
  failureThreshold: 5,
  successThreshold: 2,
  timeout: 60000
});

configureCircuit('bundlr', {
  failureThreshold: 3,
  successThreshold: 1,
  timeout: 30000
});

configureCircuit('minting-service', {
  failureThreshold: 5,
  successThreshold: 2,
  timeout: 30000
});
```

---

### 9. Incomplete Audit Trail for Wallet Operations
**File:** `src/wallets/userWallet.ts`  
**Severity:** üü† HIGH - Compliance  
**Impact:** Cannot trace wallet security incidents

**Problem:**
Wallet audit logging is incomplete:

**Logged:**
- ‚úÖ Connection events (user_wallet_connections table)
- ‚úÖ Disconnection events

**Not Logged:**
- ‚ùå Failed connection attempts (important for security)
- ‚ùå Rate limit violations
- ‚ùå Invalid signature attempts
- ‚ùå Nonce replay attacks
- ‚ùå Wallet ownership verification checks
- ‚ùå Primary wallet changes

**Consequence:**
- Cannot detect brute force attacks
- Cannot audit security incidents
- Compliance issues for financial regulations
- No forensic trail for disputes

**Fix:**
Add comprehensive audit logging:
```typescript
// Log failed attempts
await this.db.query(`
  INSERT INTO wallet_security_events
  (user_id, event_type, wallet_address, ip_address, reason, created_at)
  VALUES ($1, $2, $3, $4, $5, NOW())
`, [userId, 'CONNECTION_FAILED', walletAddress, ipAddress, reason]);

// Log rate limit violations
await this.db.query(`
  INSERT INTO wallet_security_events
  (user_id, event_type, ip_address, reason, created_at)
  VALUES ($1, 'RATE_LIMIT_EXCEEDED', $2, $3, NOW())
`, [userId, ipAddress, 'Exceeded connection rate limit']);
```

---

### 10. Priority Fee Calculation Edge Cases
**File:** `src/services/MetaplexService.ts`  
**Severity:** üü† HIGH - Transaction Failures  
**Impact:** Transactions may fail or overpay

**Problem:**
Priority fee calculation has edge cases not handled:
```typescript
async getPriorityFee(): Promise<number> {
  // Check cache first
  if (this.priorityFeeCache && 
      (Date.now() - this.priorityFeeCache.timestamp) < PRIORITY_FEE_CACHE_TTL_MS) {
    return this.priorityFeeCache.fee; // ‚ùå Could return stale fee during network congestion
  }

  const recentFees = await this.connection.getRecentPrioritizationFees();
  
  if (recentFees.length === 0) {
    return config.solana.defaultPriorityFee; // ‚ùå May be too low during congestion
  }

  const fees = recentFees
    .map(f => f.prioritizationFee)
    .filter(f => f > 0) // ‚ùå What if all fees are 0?
    .sort((a, b) => a - b);

  if (fees.length === 0) {
    return config.solana.defaultPriorityFee; // ‚ùå Same issue
  }

  const medianFee = fees[Math.floor(fees.length / 2)];
  let calculatedFee = Math.ceil(medianFee * 1.2);
  
  // ‚ùå 20% buffer may not be enough during rapid congestion
  
  calculatedFee = Math.max(calculatedFee, config.solana.minPriorityFee);
  calculatedFee = Math.min(calculatedFee, config.solana.maxPriorityFee);
  
  // ‚ùå No consideration of transaction priority/urgency
  
  return calculatedFee;
}
```

**Edge Cases Not Handled:**
1. All recent fees are 0 (network quiet) ‚Üí Uses default, may fail if suddenly congested
2. Rapid network congestion ‚Üí 10s cache too long, median+20% too conservative
3. Outlier fees (spam attacks) ‚Üí Median may not reflect actual required fee
4. No priority levels ‚Üí All transactions pay same fee regardless of urgency
5. No feedback loop ‚Üí Failed transactions don't increase fee for retry

**Consequence:**
- Transactions fail due to insufficient fee during congestion
- Overpayment during quiet periods
- No way to prioritize urgent mints
- Retry failures without fee adjustment

**Fix:**
```typescript
async getPriorityFee(priority: 'LOW' | 'NORMAL' | 'HIGH' = 'NORMAL'): Promise<number> {
  // Shorter cache during congestion
  const cacheAge = Date.now() - (this.priorityFeeCache?.timestamp || 0);
  const cacheTTL = this.isNetworkCongested ? 2000 : 10000; // 2s vs 10s
  
  if (this.priorityFeeCache && cacheAge < cacheTTL) {
    return this.applyPriorityMultiplier(this.priorityFeeCache.fee, priority);
  }

  const recentFees = await this.connection.getRecentPrioritizationFees();
  
  // Use 75th percentile instead of median for better reliability
  const fees = recentFees
    .map(f => f.prioritizationFee)
    .filter(f => f > 0)
    .sort((a, b) => a - b);

  const percentile75 = fees[Math.floor(fees.length * 0.75)] || config.solana.defaultPriorityFee;
  
  // Adaptive buffer based on fee trend
  const buffer = this.calculateAdaptiveBuffer(fees);
  let calculatedFee = Math.ceil(percentile75 * buffer);
  
  calculatedFee = Math.max(calculatedFee, config.solana.minPriorityFee);
  calculatedFee = Math.min(calculatedFee, config.solana.maxPriorityFee);
  
  this.updateCongestionStatus(fees);
  
  return this.applyPriorityMultiplier(calculatedFee, priority);
}

private applyPriorityMultiplier(baseFee: number, priority: string): number {
  const multipliers = { LOW: 0.8, NORMAL: 1.0, HIGH: 1.5 };
  return Math.ceil(baseFee * multipliers[priority]);
}

private calculateAdaptiveBuffer(fees: number[]): number {
  if (fees.length < 2) return 1.2;
  
  // If fees are trending up, use larger buffer
  const recentAvg = fees.slice(-10).reduce((a, b) => a + b, 0) / 10;
  const olderAvg = fees.slice(0, 10).reduce((a, b) => a + b, 0) / 10;
  
  return recentAvg > olderAvg * 1.5 ? 1.5 : 1.2; // 50% vs 20% buffer
}
```

---

### 11. Distributed Lock Expiry Without Extension
**File:** `src/utils/distributed-lock.ts`  
**Severity:** üü† HIGH - Correctness  
**Impact:** Long operations lose locks mid-execution

**Problem:**
Locks have fixed 30s TTL but operations can take longer:
```typescript
export async function withLock<T>(
  key: string,
  ttlMs: number, // Usually 30000 (30s)
  fn: () => Promise<T>
): Promise<T> {
  let lock: Lock | null = null;

  try {
    lock = await acquireRedisLock(key, ttlMs);
    
    if (!lock) {
      throw new Error(`Failed to acquire lock for: ${key}`);
    }

    // ‚ùå If fn() takes > 30s, lock expires before completion
    // ‚ùå Another process can acquire lock while fn() still running
    // ‚ùå Race condition and duplicate processing
    return await fn();

  } finally {
    if (lock) {
      await releaseRedisLock(lock);
      // ‚ùå May try to release already-expired lock
    }
  }
}
```

**Scenarios Where This Fails:**
1. NFT minting during network congestion (can take 60-90s)
2. Bundlr metadata upload (can take 45s)
3. Database transaction with multiple operations (can take 40s)
4. Blockchain confirmation waiting (can take 60s)

**Consequence:**
- Duplicate mints for same ticket
- Duplicate database updates
- Race conditions in critical sections
- Data corruption

**Fix:**
Implement lock extension/heartbeat:
```typescript
export async function withLock<T>(
  key: string,
  ttlMs: number,
  fn: () => Promise<T>
): Promise<T> {
  let lock: Lock | null = null;
  let extensionInterval: NodeJS.Timeout | null = null;

  try {
    lock = await acquireRedisLock(key, ttlMs);
    
    if (!lock) {
      throw new Error(`Failed to acquire lock for: ${key}`);
    }

    // Extend lock every 20s (for 30s TTL)
    extensionInterval = setInterval(async () => {
      if (lock && redisClient) {
        await redisClient.pexpire(lock.key, ttlMs);
        logger.debug('Extended lock', { key, ttl: ttlMs });
      }
    }, Math.floor(ttlMs * 0.66)); // Extend at 66% of TTL

    return await fn();

  } finally {
    if (extensionInterval) {
      clearInterval(extensionInterval);
    }
    
    if (lock) {
      await releaseRedisLock(lock);
    }
  }
}
```

---

### 12. Job History Memory Leak
**File:** `src/queues/job-history.ts`  
**Severity:** üü† HIGH - Memory Leak  
**Impact:** Service crashes after extended runtime

**Problem:**
Job history cleanup has race condition and inefficiency:
```typescript
// Retention: 24 hours
private retention = 24 * 60 * 60 * 1000;

// Cleanup runs hourly
setInterval(() => this.cleanup(), 60 * 60 * 1000);

private cleanup(): void {
  const now = Date.now();
  const cutoff = now - this.retention;
  
  // ‚ùå Linear scan of entire history Map on every cleanup
  for (const [jobId, entry] of this.history.entries()) {
    if (entry.completedAt < cutoff) {
      this.history.delete(jobId);
      
      // Remove from ticketId index
      const ticketEntries = this.ticketIdIndex.get(entry.ticketId);
      if (ticketEntries) {
        // ‚ùå Another linear scan
        const index = ticketEntries.findIndex(e => e.jobId === jobId);
        if (index !== -1) {
          ticketEntries.splice(index, 1);
        }
        
        if (ticketEntries.length === 0) {
          this.ticketIdIndex.delete(entry.ticketId);
        }
      }
    }
  }
  
  // ‚ùå No check if cleanup takes too long
  // ‚ùå Blocks event loop during cleanup
  // ‚ùå No protection against concurrent cleanup
}
```

**Additional Problems:**
- Max 10k entries limit not enforced
- No LRU eviction when limit reached
- Cleanup blocks event loop for large histories
- Race condition if cleanup runs while adding entries

**Consequence:**
- Memory grows beyond 10k limit
- Event loop lag during cleanup
- Service unresponsive during cleanup
- Potential OOM

**Fix:**
```typescript
private history = new LRU<string, JobHistoryEntry>({
  max: 10000,
  ttl: 24 * 60 * 60 * 1000, // 24 hours
  updateAgeOnGet: false,
  dispose: (entry, key) => {
    // Clean up ticket index when entry evicted
    this.removeFromTicketIndex(entry.ticketId, key);
  }
});

// Async cleanup with batching
private async cleanup(): Promise<void> {
  if (this.cleanupInProgress) return;
  this.cleanupInProgress = true;
  
  try {
    const now = Date.now();
    const cutoff = now - this.retention;
    const toDelete: string[] = [];
    
    // Batch collect expired entries
    for (const [jobId, entry] of this.history.entries()) {
      if (entry.completedAt < cutoff) {
        toDelete.push(jobId);
      }
      
      // Yield to event loop every 100 entries
      if (toDelete.length % 100 === 0) {
        await new Promise(resolve => setImmediate(resolve));
      }
    }
    
    // Batch delete
    for (const jobId of toDelete) {
      this.history.delete(jobId);
    }
    
    logger.info('Job history cleanup complete', {
      deleted: toDelete.length,
      remaining: this.history.size
    });
  } finally {
    this.cleanupInProgress = false;
  }
}
```

---

## üü° MEDIUM PRIORITY ISSUES (Technical Debt)

### 13. Hardcoded Configuration Values
**Files:** Multiple throughout codebase  
**Severity:** üü° MEDIUM - Maintainability  
**Impact:** Difficult to tune performance

**Problem:**
Many configuration values are hardcoded instead of environment variables:

**Examples:**
```typescript
// src/queues/mintQueue.ts
const LOCK_TTL_MS = 60000; // ‚ùå Should be configurable
const CONFIRMATION_TIMEOUT_MS = 60000; // ‚ùå Should be configurable
const CONCURRENCY = 3; // ‚ùå Should be configurable

// src/queues/dlq-processor.ts
const BASE_DELAY_MS = 30000; // ‚ùå Should be configurable
const MAX_DELAY_MS = 3600000; // ‚ùå Should be configurable
const MAX_RETRIES = 5; // ‚ùå Should be configurable

// src/middleware/rate-limit.ts
const RATE_LIMIT_USER_MAX = 5; // ‚ùå Should be per-tenant configurable
const RATE_LIMIT_WINDOW_SECONDS = 60; // ‚ùå Should be configurable

// src/utils/circuit-breaker.ts
const DEFAULT_CONFIG = {
  failureThreshold: 5, // ‚ùå Should be per-circuit configurable
  timeout: 30000 // ‚ùå Should be configurable
};

// src/services/MetaplexService.ts
const PRIORITY_FEE_CACHE_TTL_MS = 10000; // ‚ùå Should be configurable
```

**Consequence:**
- Cannot tune performance without code changes
- Different environments require different values
- A/B testing impossible
- Hot-reloading changes requires restart

**Fix:**
Move to environment variables with defaults:
```typescript
const LOCK_TTL_MS = parseInt(process.env.MINT_LOCK_TTL_MS || '60000');
const CONFIRMATION_TIMEOUT_MS = parseInt(process.env.MINT_CONFIRMATION_TIMEOUT_MS || '60000');
const CONCURRENCY = parseInt(process.env.MINT_QUEUE_CONCURRENCY || '3');
```

---

### 14. Inconsistent Error Handling Patterns
**Files:** Throughout codebase  
**Severity:** üü° MEDIUM - Code Quality  
**Impact:** Debugging difficulty, inconsistent errors

**Problem:**
Error handling patterns vary across the codebase:

**Pattern 1 - Return null:**
```typescript
// src/queues/job-history.ts
getMintAddress(ticketId: string): string | null {
  const entries = this.ticketIdIndex.get(ticketId);
  if (!entries) return null; // ‚ùå Silent failure
  // ...
}
```

**Pattern 2 - Return result object:**
```typescript
// src/wallets/userWallet.ts
async connectWallet(...): Promise<ConnectionResult> {
  return {
    success: false,
    message: 'Wallet connection failed', // ‚ùå Inconsistent with exceptions
    error: error.message
  };
}
```

**Pattern 3 - Throw custom errors:**
```typescript
// src/errors/index.ts
throw new WalletError(
  'Failed to connect wallet',
  ErrorCode.WALLET_CONNECTION_FAILED,
  400
);
```

**Pattern 4 - Throw generic errors:**
```typescript
// src/utils/distributed-lock.ts
throw new Error(`Failed to acquire lock for: ${key}`); // ‚ùå Not using custom error classes
```

**Consequence:**
- Callers don't know which pattern to expect
- Some errors not logged properly
- Some errors not caught by error handlers
- Inconsistent API responses
- Difficult to add global error handling

**Fix:**
Standardize on throwing custom errors with error codes:
```typescript
// Always throw custom errors
if (!lock) {
  throw new LockError(
    `Failed to acquire lock for: ${key}`,
    ErrorCode.LOCK_ACQUISITION_FAILED,
    503,
    { key, retries: 3 }
  );
}

// Never return error objects, always throw
async connectWallet(...): Promise<WalletConnection> {
  // ... 
  if (!verified) {
    throw new WalletError(
      'Invalid signature',
      ErrorCode.SIGNATURE_INVALID,
      401
    );
  }
  
  return walletConnection; // Only return on success
}
```

---

### 15. Missing Request Correlation Across Services
**Files:** Service communication layer  
**Severity:** üü° MEDIUM - Observability  
**Impact:** Cannot trace requests across services

**Problem:**
Internal service calls don't propagate request IDs:
```typescript
// src/routes/internal-mint.routes.ts
async (request, reply) => {
  const signature = generateHmacSignature(...);
  
  const response = await fetch(mintingServiceUrl, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
      'x-internal-service': 'blockchain-service',
      'x-timestamp': timestamp,
      'x-internal-signature': signature
      // ‚ùå Missing x-request-id propagation
      // ‚ùå Missing x-correlation-id propagation
    },
    body: JSON.stringify(request.body)
  });
}
```

**Consequence:**
- Cannot trace requests across service boundaries
- Debugging distributed transactions difficult
- No correlation between logs across services
- Cannot measure end-to-end latency

**Fix:**
```typescript
const response = await fetch(mintingServiceUrl, {
  method: 'POST',
  headers: {
    'Content-Type': 'application/json',
    'x-internal-service': 'blockchain-service',
    'x-timestamp': timestamp,
    'x-internal-signature': signature,
    'x-request-id': request.requestId, // ‚úÖ Propagate request ID
    'x-correlation-id': request.correlationId || request.requestId // ‚úÖ Correlation
  },
  body: JSON.stringify(request.body)
});
```

---

### 16. No Graceful Degradation for Redis Failures
**Files:** Multiple Redis-dependent features  
**Severity:** üü° MEDIUM - Resilience  
**Impact:** Service degradation instead of outage

**Problem:**
Some features fail hard when Redis is unavailable, others fail silently:

**Fail Hard (Service Breaks):**
```typescript
// src/wallets/userWallet.ts
async generateConnectionNonce(userId: string): Promise<NonceResult> {
  if (!redisClient) {
    throw new WalletError( // ‚ùå Breaks wallet connections completely
      'Redis not initialized for nonce generation',
      ErrorCode.SERVICE_UNAVAILABLE,
      503
    );
  }
  // ...
}
```

**Fail Open (Security Risk):**
```typescript
// src/middleware/rate-limit.ts
if (!redisClient) {
  logger.warn('Redis unavailable for rate limiting, allowing request');
  return { allowed: true, remaining: RATE_LIMIT_USER_MAX }; // ‚ùå No rate limiting!
}
```

**Consequence:**
- Wallet connections completely blocked when Redis down
- Rate limiting disabled when Redis down (security risk)
- Idempotency disabled when Redis down (duplicate processing)
- No middle ground between "completely broken" and "security disabled"

**Fix:**
Implement degraded mode with in-memory fallbacks and limits:
```typescript
// Degraded mode for nonces - use database instead
if (!redisClient) {
  logger.warn('Redis unavailable, using database for nonces (degraded mode)');
  
  // Store nonce in PostgreSQL with expiry
  await db.query(`
    INSERT INTO temporary_nonces (nonce, user_id, expires_at)
    VALUES ($1, $2, NOW() + INTERVAL '5 minutes')
  `, [nonce, userId]);
  
  // Cleanup expired nonces
  await db.query(`DELETE FROM temporary_nonces WHERE expires_at < NOW()`);
}

// Degraded mode for rate limiting - use in-memory with conservative limits
if (!redisClient) {
  logger.warn('Redis unavailable, using in-memory rate limiting (degraded mode)');
  
  // More conservative limits in degraded mode
  const degradedLimits = {
    user: Math.floor(RATE_LIMIT_USER_MAX * 0.5), // 50% of normal
    ip: Math.floor(RATE_LIMIT_IP_MAX * 0.5)
  };
  
  return checkMemoryLimit(key, degradedLimits.user, window);
}
```

---

### 17. Insufficient Monitoring Metrics
**Files:** `src/utils/metrics.ts`, `src/utils/blockchain-metrics.ts`  
**Severity:** üü° MEDIUM - Observability  
**Impact:** Cannot diagnose production issues

**Problem:**
Missing important metrics for production monitoring:

**Existing Metrics:** ‚úÖ
- Mint success/failure counters
- RPC call duration
- Queue job duration
- Circuit breaker states
- HTTP request counters

**Missing Metrics:** ‚ùå
- Distributed lock acquisition failures
- Distributed lock hold time (detect deadlocks)
- Idempotency cache hit rate
- Rate limit rejection rate per tenant
- Load shedding rejection rate by priority
- Bulkhead queue depth per operation type
- Nonce generation/verification rate
- Wallet connection success rate
- Transaction confirmation time by commitment level
- Priority fee actual vs expected
- DLQ category breakdown
- Job history size
- WebSocket reconnection count
- Secrets manager call duration/failures

**Consequence:**
- Cannot detect lock contention issues
- Cannot see if idempotency is working
- Cannot identify abusive tenants
- Cannot tune bulkhead limits
- Cannot optimize priority fee calculation
- Cannot measure wallet security effectiveness

**Fix:**
Add comprehensive metrics:
```typescript
// src/utils/metrics.ts

export const lockAcquisitionDuration = new Histogram({
  name: 'blockchain_lock_acquisition_duration_ms',
  help: 'Time to acquire distributed lock',
  labelNames: ['lock_type', 'status'],
  buckets: [10, 50, 100, 500, 1000, 5000]
});

export const lockHoldDuration = new Histogram({
  name: 'blockchain_lock_hold_duration_ms',
  help: 'Time lock was held',
  labelNames: ['lock_type'],
  buckets: [100, 500, 1000, 5000, 10000, 30000, 60000]
});

export const idempotencyCacheHitRate = new Counter({
  name: 'blockchain_idempotency_cache_hits_total',
  help: 'Idempotency cache hits vs misses',
  labelNames: ['status'] // hit, miss
});

export const rateLimitRejections = new Counter({
  name: 'blockchain_rate_limit_rejections_total',
  help: 'Rate limit rejections',
  labelNames: ['tenant_id', 'limit_type']
});

export const loadSheddingRejections = new Counter({
  name: 'blockchain_load_shedding_rejections_total',
  help: 'Load shedding rejections',
  labelNames: ['priority']
});

export const bulkheadQueueDepth = new Gauge({
  name: 'blockchain_bulkhead_queue_depth',
  help: 'Current queue depth per bulkhead',
  labelNames: ['operation_type']
});
```

---

### 18. No Health Check for Bundlr/Metadata Storage
**Files:** `src/routes/health.routes.ts`  
**Severity:** üü° MEDIUM - Monitoring  
**Impact:** Cannot detect metadata upload issues

**Problem:**
Health checks cover:
- ‚úÖ PostgreSQL
- ‚úÖ Redis
- ‚úÖ Solana RPC
- ‚úÖ Treasury wallet
- ‚ùå Bundlr/Arweave storage
- ‚ùå Metaplex endpoints
- ‚ùå Minting service proxy

**Consequence:**
- Metadata uploads can fail silently
- Service reports "healthy" but cannot mint
- No alerts for Bundlr outages
- Cannot detect Metaplex issues early

**Fix:**
```typescript
// src/routes/health.routes.ts

async function checkBundlr(): Promise<HealthStatus> {
  try {
    const timeout = withTimeout(2000);
    
    // Check Bundlr node status
    const response = await Promise.race([
      fetch(`${config.solana.bundlrAddress}/info`),
      timeout
    ]);
    
    if (!response.ok) {
      return { status: 'unhealthy', message: 'Bundlr node not responding' };
    }
    
    return { status: 'healthy', latency: response.time };
  } catch (error) {
    return { status: 'unhealthy', error: error.message };
  }
}

async function checkMintingService(): Promise<HealthStatus> {
  try {
    const timeout = withTimeout(2000);
    
    const response = await Promise.race([
      fetch(`${config.services.mintingServiceUrl}/health`),
      timeout
    ]);
    
    if (!response.ok) {
      return { status: 'unhealthy', message: 'Minting service unhealthy' };
    }
    
    return { status: 'healthy' };
  } catch (error) {
    return { status: 'degraded', message: 'Minting service unreachable' };
  }
}

// Add to /health/ready endpoint
const [db, redis, solana, treasury, bundlr, mintingService] = await Promise.all([
  checkPostgres(),
  checkRedis(),
  checkSolana(),
  checkTreasury(),
  checkBundlr(), // ‚úÖ Added
  checkMintingService() // ‚úÖ Added
]);
```

---

### 19. Blockchain-First Pattern Not Fully Enforced
**Files:** `src/queues/mintQueue.ts`, transaction processing  
**Severity:** üü° MEDIUM - Data Integrity  
**Impact:** Potential data inconsistency

**Problem:**
AUDIT FIX #86, #87, #89 requires "blockchain-first" pattern (confirm on-chain THEN update DB), but implementation has gaps:

**Correctly Implemented:**
```typescript
// src/queues/mintQueue.ts - Mint flow
const mintResult = await this.metaplexService.mintNFT(params);
await confirmTransaction(mintResult.transactionSignature); // ‚úÖ Confirm first
await this.saveToDatabase(mintResult); // ‚úÖ DB after confirmation
```

**Gaps:**
```typescript
// What happens if confirmation succeeds but DB write fails?
// ‚ùå No compensation mechanism to retry DB write
// ‚ùå Blockchain has minted NFT but DB doesn't know

// What if service crashes between confirmation and DB write?
// ‚ùå No recovery mechanism to find "orphaned" mints
// ‚ùå Ticket stuck in MINTING state forever
```

**Consequence:**
- NFT exists on-chain but not in database
- Ticket appears unminted but actually has NFT
- Manual reconciliation required
- User confusion

**Fix:**
Add reconciliation for orphaned mints:
```typescript
// Periodic reconciliation job
async function reconcileOrphanedMints() {
  // Find tickets stuck in MINTING for > 5 minutes
  const stuckTickets = await db.query(`
    SELECT * FROM tickets
    WHERE status = 'MINTING'
    AND updated_at < NOW() - INTERVAL '5 minutes'
  `);
  
  for (const ticket of stuckTickets.rows) {
    // Check if NFT actually exists on-chain
    const exists = await checkNFTExists(ticket.expected_mint_address);
    
    if (exists) {
      // Update DB with actual on-chain data
      logger.warn('Reconciled orphaned mint', { ticketId: ticket.id });
      await db.query(`
        UPDATE tickets 
        SET status = 'MINTED', 
            mint_address = $1,
            reconciled_at = NOW()
        WHERE id = $2
      `, [ticket.expected_mint_address, ticket.id]);
    } else {
      // NFT doesn't exist, mark as failed
      await db.query(`
        UPDATE tickets 
        SET status = 'MINT_FAILED',
            error = 'Confirmation timeout'
        WHERE id = $1
      `, [ticket.id]);
    }
  }
}

// Run every 5 minutes
setInterval(reconcileOrphanedMints, 5 * 60 * 1000);
```

**Additional Fix - Idempotent DB writes:**
```typescript
// Make DB writes idempotent so they can be retried safely
await db.query(`
  UPDATE tickets
  SET status = 'MINTED',
      mint_address = $1,
      transaction_signature = $2,
      metadata_uri = $3,
      minted_at = NOW()
  WHERE id = $4
  AND status IN ('MINTING', 'MINT_FAILED') -- ‚úÖ Only update if not already MINTED
`, [mintAddress, signature, metadataUri, ticketId]);

// Retry DB write if it fails
await retryOperation(
  () => saveMintToDatabase(mintResult),
  'Save mint to database',
  { maxAttempts: 5, retryableErrors: ['ECONNRESET', 'ETIMEDOUT'] }
);
```

---

### 20. Missing Database Connection Pool Monitoring
**Files:** `src/config/database.ts`  
**Severity:** üü° MEDIUM - Observability  
**Impact:** Cannot detect connection pool exhaustion

**Problem:**
PostgreSQL pool has no instrumentation:
```typescript
const pool = new Pool({
  connectionString: DATABASE_URL,
  max: POOL_SIZE || 20,
  // ‚ùå No pool event listeners
  // ‚ùå No metrics on pool usage
  // ‚ùå No alerts on pool exhaustion
});
```

**Consequence:**
- Cannot see pool exhaustion before it happens
- No visibility into connection wait times
- Cannot tune pool size based on usage
- Silent failures when pool depleted

**Fix:**
```typescript
import { poolUsage, poolWaitTime } from './metrics';

const pool = new Pool({
  connectionString: DATABASE_URL,
  max: POOL_SIZE || 20,
  idleTimeoutMillis: 30000,
  connectionTimeoutMillis: 2000
});

// Monitor pool events
pool.on('connect', (client) => {
  poolUsage.labels('active').inc();
  logger.debug('Pool client connected', {
    total: pool.totalCount,
    idle: pool.idleCount,
    waiting: pool.waitingCount
  });
});

pool.on('remove', (client) => {
  poolUsage.labels('active').dec();
});

pool.on('error', (err, client) => {
  logger.error('Pool client error', { error: err.message });
  poolErrors.inc();
});

// Periodically report pool stats
setInterval(() => {
  poolUsage.labels('total').set(pool.totalCount);
  poolUsage.labels('idle').set(pool.idleCount);
  poolUsage.labels('waiting').set(pool.waitingCount);
  
  if (pool.waitingCount > 0) {
    logger.warn('Pool has waiting clients', {
      waiting: pool.waitingCount,
      active: pool.totalCount - pool.idleCount,
      idle: pool.idleCount
    });
  }
}, 10000);

// Add metrics
export const poolUsage = new Gauge({
  name: 'blockchain_db_pool_connections',
  help: 'Database connection pool usage',
  labelNames: ['state'] // total, active, idle, waiting
});

export const poolErrors = new Counter({
  name: 'blockchain_db_pool_errors_total',
  help: 'Database connection pool errors'
});
```

---

## üîµ LOW PRIORITY ISSUES (Nice to Have)

### 21. Code Duplication in Validation
**Files:** Multiple validators  
**Severity:** üîµ LOW - Code Quality  
**Impact:** Maintainability

**Problem:**
Base58 validation duplicated across files:
- `src/schemas/validation.ts`
- `src/middleware/validation.ts`
- `src/wallets/userWallet.ts`

**Fix:**
Extract to shared utility and reuse.

---

### 22. Magic Numbers Throughout Codebase
**Files:** Throughout  
**Severity:** üîµ LOW - Code Quality  
**Impact:** Readability

**Examples:**
```typescript
if (balance < 0.1) // What is 0.1? Min balance threshold?
if (attempts > 30) // What is 30? Max attempts?
setTimeout(fn, 5000) // What is 5s? Retry delay?
```

**Fix:**
Replace with named constants:
```typescript
const MIN_TREASURY_BALANCE_SOL = 0.1;
const MAX_CONFIRMATION_ATTEMPTS = 30;
const RETRY_DELAY_MS = 5000;
```

---

### 23. Inconsistent Naming Conventions
**Files:** Throughout  
**Severity:** üîµ LOW - Code Quality  
**Impact:** Readability

**Problem:**
Mixed naming styles:
- `tenant_id` vs `tenantId`
- `mint_address` vs `mintAddress`
- `wallet_address` vs `walletAddress`

**Note:** Database uses snake_case (correct), TypeScript should use camelCase, need mapping layer.

---

### 24. Missing JSDoc Comments
**Files:** Most service methods  
**Severity:** üîµ LOW - Documentation  
**Impact:** Developer experience

**Problem:**
Many public methods lack JSDoc:
```typescript
async mintNFT(params: MintNFTParams): Promise<MintNFTResult> {
  // No JSDoc explaining params, return value, exceptions
}
```

**Fix:**
Add comprehensive JSDoc:
```typescript
/**
 * Mints a new NFT using Metaplex
 * 
 * @param params - Minting parameters
 * @param params.metadata - NFT metadata (uploaded to Arweave)
 * @param params.creators - Creator royalty splits (must sum to 100)
 * @param params.sellerFeeBasisPoints - Royalty percentage (1000 = 10%)
 * @returns Mint result with on-chain addresses
 * @throws {SolanaError} If RPC fails
 * @throws {MintingError} If minting fails
 */
async mintNFT(params: MintNFTParams): Promise<MintNFTResult> {
```

---

### 25. No TypeScript Strict Mode
**Files:** `tsconfig.json`  
**Severity:** üîµ LOW - Type Safety  
**Impact:** Type safety

**Problem:**
Strict mode not enabled:
```json
{
  "compilerOptions": {
    "strict": false // ‚ùå Should be true
  }
}
```

**Consequence:**
- `any` types allowed implicitly
- Null checks not enforced
- Type assertions not verified

**Fix:**
Enable strict mode and fix errors:
```json
{
  "compilerOptions": {
    "strict": true,
    "noImplicitAny": true,
    "strictNullChecks": true,
    "strictFunctionTypes": true,
    "strictPropertyInitialization": true
  }
}
```

---

## üìä SUMMARY BY SEVERITY

| Severity | Count | Must Fix Before |
|----------|-------|-----------------|
| üî¥ Critical | 6 | Production deployment |
| üü† High | 6 | Beta release |
| üü° Medium | 13 | GA release |
| üîµ Low | 5 | Ongoing improvements |
| **Total** | **30** | |

---

## üéØ RECOMMENDED FIX PRIORITY

### Phase 1 - Immediate (Before ANY Testing)
1. ‚úÖ Fix FeeManager undefined fees (#1)
2. ‚úÖ Investigate TreasuryWalletService (#2)
3. ‚úÖ Verify secrets manager integration (#3)

### Phase 2 - Before Production
4. ‚úÖ Add database transaction error handling (#4)
5. ‚úÖ Add production environment validation (#5)
6. ‚úÖ Fix transaction monitor race condition (#6)
7. ‚úÖ Fix event deduplication memory leak (#7)

### Phase 3 - Before Beta
8. ‚úÖ Add circuit breakers for all external services (#8)
9. ‚úÖ Complete wallet audit trail (#9)
10. ‚úÖ Fix priority fee edge cases (#10)
11. ‚úÖ Fix distributed lock expiry (#11)
12. ‚úÖ Fix job history memory leak (#12)

### Phase 4 - Before GA
13-25. Address medium and low priority issues

---

## üîç INVESTIGATION NEEDED

These items require deeper investigation to determine severity:

1. **Secrets Manager Integration** - Verify actual implementation exists
2. **TreasuryWalletService** - Determine if missing or just misnamed
3. **Production Deployment History** - Check if any of these issues already manifested
4. **Performance Baseline** - Establish metrics to measure improvements

---

## üìù NOTES

- This analysis is based on static code review only
- Runtime issues may reveal additional problems
- Comprehensive testing will uncover more edge cases
- Some issues may be intentional design decisions requiring clarification

